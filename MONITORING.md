# ğŸ“Š MONITORING: Seguimiento del Pipeline Gemini

## ğŸ¯ **Â¿QuÃ© monitorear?**

- **Estado del job** de Dataflow
- **Progreso** de procesamiento
- **Uso de recursos** (CPU, memoria, disco)
- **Logs** en tiempo real
- **Errores** y advertencias
- **MÃ©tricas** de rendimiento

---

## ğŸš€ **Monitoreo en tiempo real:**

### **1. Ver estado del job:**
```bash
# Listar todos los jobs
gcloud dataflow jobs list

# Ver detalles de un job especÃ­fico
gcloud dataflow jobs show [JOB_ID]

# Ver estado resumido
gcloud dataflow jobs list --format="table(id,name,state,creationTime,currentStateTime)"
```

### **2. Seguir logs en tiempo real:**
```bash
# Ver logs del job
gcloud dataflow jobs logs [JOB_ID] --follow

# Ver solo logs de error
gcloud dataflow jobs logs [JOB_ID] --level=ERROR

# Ver logs de un worker especÃ­fico
gcloud dataflow jobs logs [JOB_ID] --worker=worker-0
```

---

## ğŸŒ **Monitoreo web (Recomendado):**

### **Consola de Dataflow:**
1. Ve a: https://console.cloud.google.com/dataflow
2. Selecciona tu proyecto: `acero-470020`
3. Haz clic en tu job: `gemini-csv-to-bq`

### **InformaciÃ³n disponible:**
- **GrÃ¡fico del pipeline** en tiempo real
- **MÃ©tricas** de workers y elementos procesados
- **Logs** detallados de cada etapa
- **Estado** de cada transformaciÃ³n
- **Uso de recursos** por worker

---

## ğŸ“Š **MÃ©tricas clave a monitorear:**

### **Progreso del pipeline:**
- **Elementos procesados** por segundo
- **Workers activos** vs total
- **Tiempo estimado** restante
- **Throughput** del sistema

### **Recursos del sistema:**
- **CPU** por worker
- **Memoria** utilizada
- **Disco** de staging/temp
- **Red** (bytes transferidos)

---

## ğŸ” **Comandos de diagnÃ³stico:**

### **Ver workers del job:**
```bash
# Listar workers
gcloud dataflow jobs workers [JOB_ID]

# Ver detalles de un worker
gcloud dataflow jobs workers [JOB_ID] --worker=worker-0
```

### **Ver mÃ©tricas del job:**
```bash
# MÃ©tricas bÃ¡sicas
gcloud dataflow jobs metrics [JOB_ID]

# MÃ©tricas especÃ­ficas
gcloud dataflow jobs metrics [JOB_ID] --metric=ElementCount
```

### **Ver configuraciÃ³n del job:**
```bash
# ConfiguraciÃ³n completa
gcloud dataflow jobs describe [JOB_ID]

# Solo opciones del pipeline
gcloud dataflow jobs describe [JOB_ID] --format="value(pipelineOptions)"
```

---

## ğŸš¨ **Alertas y problemas comunes:**

### **Job atascado:**
```bash
# Ver logs de error
gcloud dataflow jobs logs [JOB_ID] --level=ERROR

# Ver workers con problemas
gcloud dataflow jobs workers [JOB_ID] --status=FAILED
```

### **Workers insuficientes:**
```bash
# Ver uso de workers
gcloud dataflow jobs workers [JOB_ID] --format="table(id,status,state,workItems)"

# Aumentar workers (requiere cancelar y reiniciar)
# Editar config.py: aumentar num_workers
```

### **Problemas de memoria:**
```bash
# Ver logs de OOM
gcloud dataflow jobs logs [JOB_ID] | grep -i "out of memory"

# Ver mÃ©tricas de memoria
gcloud dataflow jobs metrics [JOB_ID] --metric=MemoryUsage
```

---

## ğŸ“ˆ **Script de monitoreo automÃ¡tico:**

### **Crear script de monitoreo:**
```bash
cat > monitor_gemini.sh << 'EOF'
#!/bin/bash
# ğŸ“Š Script de monitoreo automÃ¡tico para Gemini

JOB_ID="$1"
if [ -z "$JOB_ID" ]; then
    echo "âŒ Uso: $0 [JOB_ID]"
    echo "   ObtÃ©n el JOB_ID con: gcloud dataflow jobs list"
    exit 1
fi

echo "ğŸ” Monitoreando job Gemini: $JOB_ID"
echo "=================================="

while true; do
    clear
    echo "ğŸ“Š MONITOREO GEMINI - $(date)"
    echo "=================================="
    
    # Estado del job
    echo "ğŸ¯ Estado del job:"
    gcloud dataflow jobs show "$JOB_ID" --format="value(state)" 2>/dev/null || echo "   Job no encontrado"
    
    # Workers activos
    echo ""
    echo "ğŸ‘¥ Workers activos:"
    gcloud dataflow jobs workers "$JOB_ID" --format="value(status)" 2>/dev/null | grep -c "RUNNING" || echo "   0"
    
    # Ãšltimos logs
    echo ""
    echo "ğŸ“ Ãšltimos logs:"
    gcloud dataflow jobs logs "$JOB_ID" --limit=3 2>/dev/null | tail -3 || echo "   No hay logs disponibles"
    
    echo ""
    echo "ğŸ”„ Actualizando en 10 segundos... (Ctrl+C para detener)"
    sleep 10
done
EOF

chmod +x monitor_gemini.sh
```

### **Usar script de monitoreo:**
```bash
# Ejecutar monitoreo
./monitor_gemini.sh [JOB_ID]

# Ejemplo
./monitor_gemini.sh 2024-01-15_12_34_56-1234567890
```

---

## ğŸ¯ **Indicadores de Ã©xito:**

### **âœ… Job completado exitosamente:**
- Estado: `JOB_STATE_DONE`
- Todos los workers en estado `RUNNING` o `STOPPED`
- No hay errores en logs
- MÃ©tricas muestran elementos procesados

### **âš ï¸ Job con problemas:**
- Estado: `JOB_STATE_FAILED` o `JOB_STATE_CANCELLED`
- Workers en estado `FAILED`
- Errores en logs
- MÃ©tricas estancadas

---

## ğŸ”§ **Acciones correctivas:**

### **Job fallÃ³:**
```bash
# Ver logs de error
gcloud dataflow jobs logs [JOB_ID] --level=ERROR

# Cancelar job fallido
gcloud dataflow jobs cancel [JOB_ID]

# Corregir configuraciÃ³n y reiniciar
python3 load_to_bq.py
```

### **Job lento:**
```bash
# Ver mÃ©tricas de throughput
gcloud dataflow jobs metrics [JOB_ID] --metric=ElementCount

# Aumentar workers (editar config.py)
# Reiniciar con mÃ¡s recursos
```

---

## ğŸ“± **Monitoreo mÃ³vil:**

### **Google Cloud Console App:**
- Descarga la app oficial de Google Cloud
- Accede a Dataflow desde tu mÃ³vil
- Recibe notificaciones de estado

### **Alertas por email:**
- Configura alertas en Cloud Monitoring
- Recibe notificaciones de fallos
- Monitoreo 24/7 automÃ¡tico

---

## ğŸ‰ **Â¡Monitoreo completo!**

Con estas herramientas, tendrÃ¡s **visibilidad completa** del pipeline Gemini:

- âœ… **Estado en tiempo real**
- âœ… **MÃ©tricas detalladas**
- âœ… **Logs completos**
- âœ… **Alertas automÃ¡ticas**
- âœ… **DiagnÃ³stico rÃ¡pido**

**Â¡Tu pipeline nunca estarÃ¡ solo! ğŸ“ŠğŸš€**
